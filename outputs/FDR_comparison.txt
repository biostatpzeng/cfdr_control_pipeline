> ###########################################################################
> ## Numerical FDR comparison between methods ###############################
> ###########################################################################
> 
> # The output of this section of code is saved in ./outputs as a text file
> #  ./outputs/FDR_comparison.txt.
> 
> suppressWarnings(rm(list=intersect(colnames(rx),ls())))
> attach(rx)
> 
> # Shorthands
> fp=fdp_p; # FDP for p-values (BH procedure)
> f1=fdp_cf1_fdr1_adj0_dist1; # FDP using method 1
> f2=fdp_cf1_fdr2_adj0_dist1; # FDP using method 2
> f3=fdp_cf1_fdr3_adj0_dist1; # FDP using method 3
> f3b=fdp_cf1_fdr3b_adj0_dist1; # FDP using method 3b
> f4=fdp_cf1_fdr4_adj0_dist1; # FDP using method 4
> 
> f3_1=fdp_cf1_fdr3_adj0_dist1_fold1; # FDP using method 3, fold 1
> f3_2=fdp_cf1_fdr3_adj0_dist1_fold2; # FDP using method 3, fold 2
> f3_3=fdp_cf1_fdr3_adj0_dist1_fold3; # FDP using method 3, fold 3
> 
> # We separately consider the cases n1p+ n1pq=0 and n1p+n1pq>0, since 
> #  failure of FDR control tends to occur most severely at n1p+n1pq=0
> xx=n1p+n1pq; 
> x0=which(xx==0)
> x1=which(xx>0)
> 
> alpha=0.1 # universal
> 
> 
> # FDR control at n1p+n1pq=0. In this case, any rejection of the 
> #  null constitutes a false discovery, so the FDP is either 0 or 1.
> #  We thus use a one-tailed binomial test of proportion to see if 
> #  the FDR exceeds alpha (0.1).
> n=length(x0)
> prop.test(sum(f1[x0]),n,alpha,alternative="greater") # controlled using method 1

	1-sample proportions test with continuity correction

data:  sum(f1[x0]) out of n, null probability alpha
X-squared = 0.83645, df = 1, p-value = 0.8198
alternative hypothesis: true p is greater than 0.1
95 percent confidence interval:
 0.09342796 1.00000000
sample estimates:
         p 
0.09759547 

> prop.test(sum(f2[x0]),n,alpha,alternative="greater") # NOT controlled using method 2

	1-sample proportions test with continuity correction

data:  sum(f2[x0]) out of n, null probability alpha
X-squared = 537.61, df = 1, p-value < 2.2e-16
alternative hypothesis: true p is greater than 0.1
95 percent confidence interval:
 0.1548819 1.0000000
sample estimates:
        p 
0.1600536 

> prop.test(sum(f3[x0]),n,alpha,alternative="greater") # NOT controlled using method 3

	1-sample proportions test with continuity correction

data:  sum(f3[x0]) out of n, null probability alpha
X-squared = 4308.2, df = 1, p-value < 2.2e-16
alternative hypothesis: true p is greater than 0.1
95 percent confidence interval:
 0.263642 1.000000
sample estimates:
        p 
0.2699323 

> prop.test(sum(f3b[x0]),n,alpha,alternative="greater") # controlled using method 3b

	1-sample proportions test with continuity correction

data:  sum(f3b[x0]) out of n, null probability alpha
X-squared = 0.07001, df = 1, p-value = 0.3957
alternative hypothesis: true p is greater than 0.1
95 percent confidence interval:
 0.09649446 1.00000000
sample estimates:
        p 
0.1007221 

> prop.test(sum(f4[x0]),n,alpha,alternative="greater") # controlled using method 4

	1-sample proportions test with continuity correction

data:  sum(f4[x0]) out of n, null probability alpha
X-squared = 0.019058, df = 1, p-value = 0.5549
alternative hypothesis: true p is greater than 0.1
95 percent confidence interval:
 0.09539914 1.00000000
sample estimates:
         p 
0.09960545 

> prop.test(sum(c(f3_1[x0],f3_2[x0],f3_3[x0])),
+           3*n,alpha,alternative="greater") # controlled within-fold using method 3a

	1-sample proportions test with continuity correction

data:  sum(c(f3_1[x0], f3_2[x0], f3_3[x0])) out of 3 * n, null probability alpha
X-squared = 0.0005404, df = 1, p-value = 0.5093
alternative hypothesis: true p is greater than 0.1
95 percent confidence interval:
 0.09750978 1.00000000
sample estimates:
         p 
0.09995285 

> 
> # When used on f1,f2,f3,f3b,f4, this test has power 90% to detect a deviation of 9.5% at 0.05
> #  significance:
> POWER=0.9; P=0.05; n=length(x0); alpha=0.1
> uniroot(function(x) qbinom(1-POWER,n,x)-qbinom(1-P,n,alpha),interval=c(0.05,0.5))$root / alpha # proportional change in alpha detectable
[1] 1.077266
> 
> 
> 
> # FDR control at n1p+n1pq>0. FDP is roughly normal for large n1p+n1pq; we
> #  use a one-sided t-test here. In general, the FDR is controlled at a 
> #  level lower than alpha when n1p+n1pq>0 (see figures). 
> t.test(f1[x1]-alpha,alternative="greater") # controlled using method 1

	One Sample t-test

data:  f1[x1] - alpha
t = -27.13, df = 14390, p-value = 1
alternative hypothesis: true mean is greater than 0
95 percent confidence interval:
 -0.02417712         Inf
sample estimates:
  mean of x 
-0.02279499 

> t.test(f2[x1]-alpha,alternative="greater") # NOT controlled using method 2

	One Sample t-test

data:  f2[x1] - alpha
t = 5.5456, df = 14390, p-value = 1.491e-08
alternative hypothesis: true mean is greater than 0
95 percent confidence interval:
 0.003847611         Inf
sample estimates:
  mean of x 
0.005470222 

> t.test(f3[x1]-alpha,alternative="greater") # NOT controlled using method 3

	One Sample t-test

data:  f3[x1] - alpha
t = 11.887, df = 14390, p-value < 2.2e-16
alternative hypothesis: true mean is greater than 0
95 percent confidence interval:
 0.0117524       Inf
sample estimates:
 mean of x 
0.01364002 

> t.test(f3b[x1]-alpha,alternative="greater") # controlled using method 3b

	One Sample t-test

data:  f3b[x1] - alpha
t = -8.8842, df = 14390, p-value = 1
alternative hypothesis: true mean is greater than 0
95 percent confidence interval:
 -0.00913331         Inf
sample estimates:
   mean of x 
-0.007706424 

> t.test(f4[x1]-alpha,alternative="greater") # controlled using method 4

	One Sample t-test

data:  f4[x1] - alpha
t = -9.1165, df = 14390, p-value = 1
alternative hypothesis: true mean is greater than 0
95 percent confidence interval:
 -0.009259911          Inf
sample estimates:
   mean of x 
-0.007844478 

> t.test(c(f3_1[x0],f3_2[x0],f3_3[x0])-alpha,
+          alternative="greater") # controlled within-fold using method 3a

	One Sample t-test

data:  c(f3_1[x0], f3_2[x0], f3_3[x0]) - alpha
t = -0.031555, df = 40298, p-value = 0.5126
alternative hypothesis: true mean is greater than 0
95 percent confidence interval:
 -0.00250483         Inf
sample estimates:
    mean of x 
-4.714757e-05 

> # When used on f1,f2,f3,f3b,f4, this test has power to detect a deviation of 11% at 0.05 significance:
> POWER=0.9; P=0.05; n=length(x1); SD=sd(c(f1,f2,f3,f3b,f4)); alpha=0.1
> (power.t.test(n=n,delta=NULL,sd=SD,sig=P,power=POWER,alt="one")$delta / alpha) + 1 # proportional change in alpha detectable
[1] 1.089628
> 
> 
> 
> # FDR comparison to p-values with n1p+n1pq=0: the FDR of the B-H method at n1p+n1pq=0 is exactly alpha,
> #  so we can use a two-sided binomial test of proportion. Method 3a cannot easily be compared in this
> #  way within-fold as it uses a different sample size to the B-H method.
> n=length(x0)
> prop.test(sum(f1[x0]),n,alpha,alternative="two") # no difference using method 1

	1-sample proportions test with continuity correction

data:  sum(f1[x0]) out of n, null probability alpha
X-squared = 0.83645, df = 1, p-value = 0.3604
alternative hypothesis: true p is not equal to 0.1
95 percent confidence interval:
 0.09265502 0.10276772
sample estimates:
         p 
0.09759547 

> prop.test(sum(f2[x0]),n,alpha,alternative="two") # FDR higher using method 2

	1-sample proportions test with continuity correction

data:  sum(f2[x0]) out of n, null probability alpha
X-squared = 537.61, df = 1, p-value < 2.2e-16
alternative hypothesis: true p is not equal to 0.1
95 percent confidence interval:
 0.1539139 0.1663889
sample estimates:
        p 
0.1600536 

> prop.test(sum(f3[x0]),n,alpha,alternative="two") # FDR higher using method 3

	1-sample proportions test with continuity correction

data:  sum(f3[x0]) out of n, null probability alpha
X-squared = 4308.2, df = 1, p-value < 2.2e-16
alternative hypothesis: true p is not equal to 0.1
95 percent confidence interval:
 0.2624549 0.2775419
sample estimates:
        p 
0.2699323 

> prop.test(sum(f3b[x0]),n,alpha,alternative="two") # no difference using method 3b

	1-sample proportions test with continuity correction

data:  sum(f3b[x0]) out of n, null probability alpha
X-squared = 0.07001, df = 1, p-value = 0.7913
alternative hypothesis: true p is not equal to 0.1
95 percent confidence interval:
 0.09570987 0.10596430
sample estimates:
        p 
0.1007221 

> prop.test(sum(f4[x0]),n,alpha,alternative="two") # no difference using method 4

	1-sample proportions test with continuity correction

data:  sum(f4[x0]) out of n, null probability alpha
X-squared = 0.019058, df = 1, p-value = 0.8902
alternative hypothesis: true p is not equal to 0.1
95 percent confidence interval:
 0.09461868 0.10482284
sample estimates:
         p 
0.09960545 

> # When used on f1,f2,f3,f3b,f4, this test has power 90% to detect a deviation of 10.5% at 0.05
> #  significance:
> POWER=0.9; P=0.05; n=length(x0); alpha=0.1
> uniroot(function(x) qbinom(1-POWER,n,x)-qbinom(1- P/2,n,alpha),interval=c(0.05,0.5))$root / alpha # proportional change in alpha detectable
[1] 1.085511
> 
> 
> 
> 
> 
> # FDR comparison to p-values with n1p+n1pq>0. The FDR of the B-H method in
> #  this case is generally <0.1, so we compare pairwise. We use a paired 
> #  Wilcoxon rank sum test. The sign of the difference is given by the sign
> #  of the pseudomedian; that is, if the pseudomedian of wilcox.test(x,y,...) 
> #  is >0, then in general x>y.
> wilcox.test(f1[x1],fp[x1],paired=T,conf.int=T) # FDP SMALLER using method 1 (ie overconservative)

	Wilcoxon signed rank test with continuity correction

data:  f1[x1] and fp[x1]
V = 19361000, p-value < 2.2e-16
alternative hypothesis: true location shift is not equal to 0
95 percent confidence interval:
 -0.01550428 -0.01392389
sample estimates:
(pseudo)median 
   -0.01469607 

> wilcox.test(f2[x1],fp[x1],paired=T,conf.int=T) # FDP larger using method 2 

	Wilcoxon signed rank test with continuity correction

data:  f2[x1] and fp[x1]
V = 38824000, p-value < 2.2e-16
alternative hypothesis: true location shift is not equal to 0
95 percent confidence interval:
 0.004894675 0.006284730
sample estimates:
(pseudo)median 
   0.005572145 

> wilcox.test(f3[x1],fp[x1],paired=T,conf.int=T) # FDP larger using method 3

	Wilcoxon signed rank test with continuity correction

data:  f3[x1] and fp[x1]
V = 41404000, p-value < 2.2e-16
alternative hypothesis: true location shift is not equal to 0
95 percent confidence interval:
 0.006224442 0.007681779
sample estimates:
(pseudo)median 
   0.006968116 

> wilcox.test(f3b[x1],fp[x1],paired=T,conf.int=T) # FDP equivalent using method 3b

	Wilcoxon signed rank test with continuity correction

data:  f3b[x1] and fp[x1]
V = 31384000, p-value = 0.4218
alternative hypothesis: true location shift is not equal to 0
95 percent confidence interval:
 -0.0008713527  0.0003853057
sample estimates:
(pseudo)median 
 -0.0002410799 

> wilcox.test(f4[x1],fp[x1],paired=T,conf.int=T) # FDP equivalent using method 4

	Wilcoxon signed rank test with continuity correction

data:  f4[x1] and fp[x1]
V = 30389000, p-value = 0.2056
alternative hypothesis: true location shift is not equal to 0
95 percent confidence interval:
 -0.0010207652  0.0002217361
sample estimates:
(pseudo)median 
 -0.0004012819 

> # It is difficult to sensibly calculate the power of a Wilcoxon test; however,
> #  the test is powerful. Approximately 20% of FDPs are equal in each comparison. We show below
> #  that we have approximately 90% power to detect a 3% difference in 
> #  Pr(FDP(method) > FDP(P)) and Pr(FDP(method) < FDP(P))
> delta=0.03 # P(FDP(method) > FDP(P)) - P(FDP(method) < FDP(P))
> equal=0.2 # P(FDP(method)=FDP(P))
> n=length(x1); np=0; ntrial=1000; P=0.05; set.seed(1)
> for (i in 1:ntrial) {
+  s=sample(c(-1,0,1),n,prob=c((1-equal-delta)/2,equal,(1-equal+delta)/2),rep=T)
+  pw=wilcox.test(s,rep(0,n),paired=T)$p.value; if (pw< P) np=np+1
+ }
> np/ntrial # power to detect difference
[1] 0.978
> 
